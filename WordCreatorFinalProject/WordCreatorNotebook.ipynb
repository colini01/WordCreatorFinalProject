{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f81b5b7",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "This project, I decided to go down a route different from the labs and made a word generator and functions that are based off of it. I didn't just make random words, I implemented some Cornell data with letter appearance probabilities they got from 40,000 words using pandas. Although the data shown in the code doesn't look the same as their data, I created number ranges using that data to more easily implement that data into this project. Then, I have a class that is an instance that holds it's own list of words it has created. The class has functions to create either one word or many at once, and a function to clear the stored list in the instance. Then, there are two external functions, one that looks at a list of words and allows you to chose words to keep in a new dictionary and define them. Finally, there is a function that has the computer create words randomly using the Cornell data until it created the same word defined in the parameter. Although having a word creator is easy to make, I tried to make it generate words that are less nonsense and more English looking and use that creator to do more than just create. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5de3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd\n",
    "from Module.classes import Words\n",
    "from Module.functions import keep_and_define, go_for_word\n",
    "# import Module.test_functions\n",
    "\n",
    "# import Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed2e0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep ENOE (y/n): n\n",
      "Keep CLAT (y/n): y\n",
      "Give definition: Descriptor of goopy ground.\n",
      "Keep VWEO (y/n): n\n",
      "Keep AFK (y/n): y\n",
      "Give definition: Away from keyboard\n",
      "Keep GOMP (y/n): y\n",
      "Give definition: When one really wants to stomp but cannot.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CLAT': 'Descriptor of goopy ground.',\n",
       " 'AFK': 'Away from keyboard',\n",
       " 'GOMP': 'When one really wants to stomp but cannot.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing off the keep_and_define function\n",
    "w = Words(length=4)\n",
    "w.clear()\n",
    "w.make_many()\n",
    "keep_and_define(w.word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9bd8cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ENOE', 'CLAT', 'VWEO', 'AFK', 'GOMP', 'GIR', 'MNE', 'EVX', 'EWO', 'HNU', 'RCN', 'RCC', 'ECR', 'UHY', 'OBN', 'RNM', 'ATE', 'IRT', 'ANI', 'TPR', 'TLA', 'SSA', 'IOA', 'OST', 'TWU', 'YOT', 'ULA', 'YLE', 'ITE', 'OGE', 'SWD', 'IAS', 'NHR', 'OAA', 'THD', 'EFV', 'NAI', 'LYE', 'OON', 'ONV', 'OAF', 'EGT', 'SEY', 'GTI', 'KIO', 'FGE', 'NSO', 'AWI', 'NCP', 'RDE', 'SCI', 'FTS', 'DII', 'SJR', 'HPN', 'HFD', 'IOS', 'KTN', 'TTK', 'NTI', 'ETA', 'ACO', 'NNK', 'OHE', 'TTH', 'RTG', 'TGO', 'VVE', 'OUU', 'AME', 'OST', 'TET', 'ETA', 'NIY', 'TLI', 'OMT', 'NTH', 'YEH', 'AAG', 'VNH', 'WUB', 'IAR', 'LEE', 'FVE', 'PED', 'NDS', 'SOD', 'OEB', 'OIW', 'REM', 'EMF', 'IKP', 'HAS', 'COA', 'AEO', 'KSO', 'FNW', 'RTC', 'TRN', 'IIA', 'TRH', 'SOD', 'SAN', 'ROB', 'LET', 'TIV', 'AAE', 'NEE', 'OEA', 'IHE', 'ITI', 'IUM', 'KAN', 'GRR', 'HLM', 'WVH', 'OSO', 'RDH', 'LAS', 'ULO', 'RRE', 'YIB', 'OEO', 'IIO', 'OEE', 'AIU', 'IOL', 'SEM', 'SFY', 'DTT', 'SEW', 'ILC', 'HTS', 'UEO', 'ONN', 'TNS', 'EAU', 'FHA', 'AIT', 'ANI', 'ENH', 'IAD', 'LWB', 'NNI', 'VNR', 'SLT', 'AAE', 'IIH', 'SER', 'TLN', 'FAA', 'IEI', 'FOA', 'DRO', 'SST', 'EGP', 'RFO', 'BTW', 'AEL', 'RII', 'VUW', 'TNO', 'SHW', 'RAP', 'TBO', 'IRM', 'NAM', 'MHT', 'UDF', 'CAH', 'ESD', 'DFR', 'THI', 'TWE', 'LAE', 'SWR', 'OFT', 'END', 'RAF', 'OAA', 'WQS', 'LEE', 'SUT', 'WUS', 'EBH', 'TLI', 'YUY', 'SOH', 'OTI', 'EET', 'OHG', 'STW', 'BHL', 'ELO', 'EEE', 'JTD', 'ENL', 'HER', 'RHP', 'NRO', 'SOS', 'INE', 'SNR', 'AIA', 'IRD', 'OVL', 'LHU', 'EBA', 'AAI', 'LDH', 'OFR', 'ALG', 'YRE', 'ELF', 'PNS', 'NLM', 'NBG', 'SER', 'DOC', 'PSO', 'TDI', 'SST', 'TUN', 'OCO', 'CHE', 'AYA', 'TRD', 'ECO', 'TDT', 'HAE', 'CLP', 'HER', 'ITS', 'KEB', 'AUP', 'TPN', 'OIE', 'ECN', 'ODA', 'EHE', 'ATT', 'EIH', 'EAT']\n",
      "It took: 243 words to get EAT.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing off go_for_word function\n",
    "\n",
    "go_for_word('EAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dcc2a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.9.5, pytest-7.4.2, pluggy-1.3.0\n",
      "rootdir: /home/coisidro/WordCreatorFinalProject\n",
      "plugins: anyio-3.2.1\n",
      "collected 4 items                                                              \u001b[0m\n",
      "\n",
      "Module/test_functions.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.50s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e9448",
   "metadata": {},
   "source": [
    "I feel like I went above and beyond for the letter bias system I created for the generator. Although doing it completely randomly could've been fine (maybe adding more funcitons to make up for the word simplicity), it was hard trying to get the generator to have a bias for certain letters over others. When I had it go completely random, I noticed letters like x, y, and z coming up too often and wanted more normal looking words. I researched a bit and saw the data and decided to use it for the project, and of course, I showed where I got it in a doc string. But, it was hard to think of a way to implement it using that exact table. I really didn't want to change it (like I was really fixated on keeping it exactly the same), but ended up believing that the number range table I made worked better for the coding logic I came up with (well it's just same values but the number lower than another is added to the one just above it). So, I feel like I put a lot of extra thought into this project than was expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
